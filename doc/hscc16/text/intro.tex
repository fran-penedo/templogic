\section{Introduction}\label{sec:intro}

%\subsection{the Two-class problem}
Machine learning deals with the construction of algorithms that can learn from data. Such algorithms operate by building a classifier from example inputs, called training data, in order to make accurate predictions on new (unseen) data \cite{bishop_pattern_2006}.
One of the main problems in machine learning is the so called \emph{two-class classification problem}. In this setting, the goal is to build a classifier that can distinguish objects belonging to one of two possible classes.
%, usually called \emph{positives} and \emph{negatives}.
This problem is of fundamental importance for two reasons. 
First, an algorithm that solves the two-class problem can be employed to construct a classifier for solving the more general multi-class problem \cite{bishop_pattern_2006}.
Second, it can be directly applied for anomaly detection, where the objective to find patterns in data that do not conform to the expected behavior.
These non-conforming patterns are often referred to as \emph{anomalies} or \emph{negatives}, interchangeably, whereas the normal working conditions are usually referred to as \emph{targets} or \emph{positives}.
Given the importance of this problem and its broad applicability, it has been the topic of several surveys and books \cite{hodge_survey_2004, isermann_faultdiagnosis_2006, chandola_anomaly_2009}.

%\subsection{specifics of our ML problem}
A specific formulation of the two-class problem is determined by several factors such as: the nature of the input data,
%the nature of the anomalies, 
the availability of labels, as well as the constraints and requirements determined by the application domain \cite{chandola_anomaly_2009}.
In this paper, we deal with data in form of finite time-series, called traces or trajectories, and we suppose that the labels of these traces are available. That is, the true class of each trace is know, either \emph{positive} or \emph{negative}, and this information is exploited during the classifier construction phase (supervised learning).
We tackle the two-class classification problem by bringing together concepts and tools from formal methods and machine learning. Our thesis is that a \emph{formal specification} of the normal working conditions can be gleaned directly from execution traces, and expressed in form of Signal Temporal Logic (STL) formulae, a specification language used in the field of formal methods to define the behaviors of continuous systems \cite{maler_monitoring_2004}.
The inferred formulae can then be applied directly as data classifiers for new traces. These ideas were pioneered by Kong and Jones \cite{kong_temporal_2014, jones_anomaly_2014} and named \emph{temporal logic inference} (TLI). This approach, while retaining many qualities of traditional classifiers, presents several advantages.
First, STL formulae have precise meaning and allow for a rich specification of the normal behaviour that is easily \emph{interpretable by humans}.
Second, anomaly detection methods commonly applied to time-series data are often model-based, i.e. they require a \emph{good} model of the system running alongside the physical system \cite{isermann_faultdiagnosis_2006}.
Third, classical machine learning methods are often over specific to the task. That is, they focus exclusively on solving the classification problem but offer no other insight on the system where they have been applied. On the contrary, TLI fits naturally as a step in the system's design workflow and its analysis and results can be employed in other phases.

%\subsection{ourapproach-verysimplified}
In this paper, we propose a new class of decision-tree based algorithms that perform temporal logic inference. In other words, we proposes a novel framework for solving the two-class classification problem involving finite-time traces using STL formulae as data classifiers.
Every algorithm grows a binary decision tree which can be translated to an STL formula and used for classification purposes.
Each node of a tree is associated with a simple formula, chosen from a finite set of primitives, and new nodes are created by finding the optimal primitive, along with its parameters, within a greedy growing procedure. 
The optimality at each step is assessed using \emph{impurity} measures, which capture how well a primitive splits the traces in the training data.
The impurity measures described in this paper are modified version of the usual impurity measures to handle finite-time trajectories and were obtained by exploiting the \emph{robustness degree} concept \cite{donze_robust_2010}.
Our novel framework presents several advantages. In particular, the proposed incremental construction procedure requires the optimization of a small and fixed number of primitives at each node. Moreover, the number of objects to be processed decreases at each iteration. This two features greatly improve the execution time and the accuracy compared to other existing algorithms.

%\subsection{outline}
This paper is organized as follows. 
In Section \ref{sec:relwwork} we briefly survey some previous research efforts related to learning temporal logic formulae.
In Section \ref{sec:stl}, we review the definition of Signal Temporal Logic, and its parameterized version PSTL used in the rest of the paper.
Our decision tree framework for classification is presented in detail in Section \ref{sec:DTFW}.
The case studies selected, maritime surveillance and fuel control system, are introduced in Section \ref{sec:case_studies} along with the modifications made to the base models and how the the datasets are generated.
In Section \ref{sec:results} we report and discuss the formulae obtained by applying our temporal logic inference algorithms.
We conclude in Section \ref{sec:conclusions} with a review of the work performed and an outlook to future research directions.
