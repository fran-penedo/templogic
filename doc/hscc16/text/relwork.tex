\section{Related work}\label{sec:relwwork}

%\subsection{Parameters mining}
Most of the recent research on logical inference, i.e., the problem of inferring from data a logical expression that describes system properties, has focused on mining only the values of parameters associated with a given temporal logic formula \cite{asarin_parametric_2012, jin_mining_2015, yang_querying_2012, bartocci_system_2015}.
That is, a designer provides a formula template such as ``The engine speed settles below $v$ m/s within $\tau$ second'' and an optimization procedure finds values for $v$ and $\tau$. The given structure reflects the (substantial) domain knowledge of the designer on the system and its properties of interest to be queried.
With this approach, it is not possible to acquire new knowledge about the system directly from data, since it requires the designer to be very specific about the form of system properties that are investigated.


%\subsection{Temporal Logic Inference}
Kong and Jones \cite{jones_anomaly_2014,kong_temporal_2014} were the first to propose methods for inferring both the formula structure and its parameters from data.
They first define a fragment of STL, called inference parametric signal temporal logic (iPSTL), and show that this fragment admits a partial order in the sense of language inclusion and robustness degree ordering among formulae.
This implies that iPSTL formulae can be organized in an infinite directed acyclic graph (DAG) 
%capturing their ordering.
%, that is, formulae in the DAG are connected 
according to how general they are (for any valuation).
This result enabled them to formulate the classification problem as an optimization problem, whose objective function involves the robustness degree, and solve it in two cyclic steps: first, optimize the formula structure by exploring the DAG, pruning and growing it, and second, optimize the formula parameters, for a fixed structure, using a nonlinear optimization algorithm.

%\subsection{Problem previous work}
%previous algorithm: any new formula needs to be evaluated from scratch
This approach presents two major disadvantages.
First, the parameter optimization routine has an high computational cost, mostly due to its nonlinear nature, and finding the optimal valuation becomes more and more challenging as the algorithm proceeds, because the dimension of the parameter space grows at each iteration. 
This problem leads to long execution times and sometimes to the production of inconsistent results.
Second, the DAG is built using an ordering on the language accepted by PSTL formulae. This has two adverse effects. First, the algorithm aims to optimize the overall formula structure, i.e. for all valuation the structure should be good, which may be too conservative. 
We are more interested in the best structure-valuation pair.
Second, while moving from one node of the DAG to another offers guarantees in terms of the language of the formulae involved, this does not imply that a move along the DAG
%changing the formula structure according to the DAG 
will lead to a better performing formula in terms of the misclassification rate, which is the metric of interest for a classification problem.

